{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from tensorflow.keras.models import load_model # type: ignore\n",
    "from tensorflow.keras.preprocessing import image # type: ignore\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input # type: ignore\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = (224, 224)\n",
    "NUM_CENTROIDS_PER_PERSON = 16\n",
    "NUM_PEOPLE = 488\n",
    "\n",
    "# Load model and data\n",
    "base_model = load_model('models/resnet50.h5')\n",
    "feature_extractor = tf.keras.Model(inputs=base_model.input, outputs=base_model.get_layer('conv5_block3_out').output)\n",
    "\n",
    "\n",
    "with open(\"../models/feature_maps/class_indices.json\", \"r\") as f:\n",
    "    index_to_class = {v: k for k, v in json.load(f).items()}\n",
    "\n",
    "def detect_and_crop_face(image):\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "        detected_faces = []\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 1) \n",
    "            side_length = max(w, h)  \n",
    "            half_side = side_length // 2\n",
    "            center_x = x + w // 2\n",
    "            center_y = y + h // 2\n",
    "        \n",
    "            x1 = max(center_x - half_side, 0)\n",
    "            y1 = max(center_y - half_side, 0)\n",
    "            x2 = min(center_x + half_side, image.shape[1])\n",
    "            y2 = min(center_y + half_side, image.shape[0])\n",
    "            \n",
    "            face_img = image[y1:y2, x1:x2]\n",
    "            detected_faces.append(face_img)  \n",
    "        return detected_faces\n",
    "\n",
    "def preprocess_image(self, img_path):\n",
    "      img = cv2.imread(img_path)\n",
    "      if img is None:\n",
    "            raise ValueError(f\"Error: Could not read image {img_path}.\")\n",
    "      detected_faces = detect_and_crop_face(img)\n",
    "      if not detected_faces:\n",
    "            print(\"Error: No faces detected.\")\n",
    "            return None, None\n",
    "      img = detected_faces[0]\n",
    "      img = cv2.resize(img, self.img_size)\n",
    "      img_array = image.img_to_array(img)\n",
    "      return preprocess_input(np.expand_dims(img_array, axis=0)), img\n",
    "\n",
    "def load_feature_maps(self, data_dir=\"../models/data\"):\n",
    "      feature_maps = []\n",
    "      image_paths = []\n",
    "      for class_dir in os.listdir(data_dir):\n",
    "            if os.path.isdir(os.path.join(data_dir, class_dir)):\n",
    "                  for img_file in glob.glob(os.path.join(data_dir, class_dir, \"*.jpeg\")):\n",
    "                        img_array, _ = self.preprocess_image(img_file)\n",
    "                        feature_map = self.feature_extractor.predict(img_array)\n",
    "                        feature_maps.append(feature_map.flatten())\n",
    "                        image_paths.append(img_file)\n",
    "      return np.array(feature_maps), image_paths\n",
    "\n",
    "\n",
    "def find_similar_images(self, input_feature, num_similar=3):\n",
    "      distances = np.linalg.norm(self.feature_maps - input_feature, axis=1)\n",
    "      closest_indices = np.argsort(distances)[:num_similar]\n",
    "      return [self.image_paths[i] for i in closest_indices]\n",
    "\n",
    "def visualize_similar_images(self, img_path, num_similar=3):\n",
    "      input_feature, _ = self.preprocess_image(img_path)\n",
    "      input_feature = self.feature_extractor.predict(input_feature).flatten()\n",
    "      similar_images = self.find_similar_images(input_feature, num_similar)\n",
    "      \n",
    "      return similar_images\n",
    "\n",
    "\n",
    "image_paths = [\n",
    "    'path_to_image_1.jpg',\n",
    "    'path_to_image_2.jpg',\n",
    "    'path_to_image_3.jpg',\n",
    "    'path_to_image_4.jpg',\n",
    "    'path_to_image_5.jpg'\n",
    "]\n",
    "\n",
    "# Hàm để kiểm tra\n",
    "def test_visualize_similar_images(image_paths):\n",
    "    for img_path in image_paths:\n",
    "        try:\n",
    "            similar_images = visualize_similar_images(img_path, num_similar=3)\n",
    "            print(f\"Similar images for {img_path}:\")\n",
    "            for similar_img in similar_images:\n",
    "                print(f\" - {similar_img}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Error for {img_path}: {e}\")\n",
    "\n",
    "# Gọi hàm kiểm tra\n",
    "test_visualize_similar_images(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
